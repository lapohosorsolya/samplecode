#!/usr/bin/env python3
import os, sys, argparse
import numpy as np
import pandas as pd
import scanpy as sc
import anndata
import time
from datetime import datetime
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import svm
from scgo import ldmethods

'''
Train and test an SVM to identify intact or broken single cells in scRNA-seq data.
'''

normal = '\033[0m'
blue = '\033[94m' 
red = '\033[93m'


if __name__ == '__main__':

    first_tic = time.process_time()
    now = datetime.now()


    ###### PARSE ARGS ######


    parser = argparse.ArgumentParser(description = 'Use this program to run clustering after makefeatures.py')
    parser.add_argument('workdir', help = 'full path to directory where output files will be written (should contain the output of makefeatures.py)', type = str)
    parser.add_argument('--test', help = 'whether to split the data into training and testing sets (if True, the anndata object must have a true_annotation bool column in obs)', default = False, type = bool)
    parser.add_argument('--batchremove', help = 'whether batch effect removal should be done (using ComBat built into scanpy)', default = False, type = bool)
    parser.add_argument('--genesets', help = 'whether gene set features should be used', default = True, type = bool)
    args = parser.parse_args()
    
    work_dir = args.workdir
    split_data = args.test
    batch = args.batchremove
    genesets = args.genesets
    genesets = False

    ###### READ INPUTS ######

    param_file = work_dir + 'params.tsv'
    data_file = work_dir + 'intermediate_data.h5ad'
    feature_dict_file = work_dir + 'feature_dict.tsv'
    feature_list_file = work_dir + 'ranked_feature_list.txt'

    # get relevant information from the params.tsv file generated by makefeatures.py
    if not os.path.isfile(param_file):
        print(red + 'File does not exist: {}\n'.format(param_file) + normal)
        sys.exit(2)
    else:
        params = pd.read_csv(param_file, sep = '\t', header = 0)
        param_dict = params.set_index('var')['val'].to_dict()

    # read anndata file (intermediate generated by makefeatures.py)
    if not os.path.isfile(data_file):
        print(red + 'File does not exist: {}\n'.format(data_file) + normal)
        sys.exit(2)
    else:
        origdata = sc.read_h5ad(data_file)

    # read feature dict
    if not os.path.isfile(feature_dict_file):
        print(red + 'File does not exist: {}\n'.format(feature_dict_file) + normal)
        sys.exit(2)
    else:
        print(blue + 'Reading feature dict from {}'.format(feature_dict_file) + normal)
        feature_dict = {}
        feature_df = pd.read_csv(feature_dict_file, sep = '\t')
        for index, row in feature_df.iterrows():
            feature_dict[row['feature']] = row['genes'].split(',')

    # read feature list
    if not os.path.isfile(feature_list_file):
        print(red + 'File does not exist: {}\n'.format(feature_list_file) + normal)
        sys.exit(2)
    else:
        print(blue + 'Reading feature list from {}'.format(feature_list_file) + normal)
        with open(feature_list_file) as f:
            feature_list = [ line.rstrip() for line in f ]
    

    ###### ORGANIZE DATA ######


    # split data to train and test if needed
    if split_data == True:
        if 'true_annotation' not in origdata.obs.columns:
            origdata.obs['true_annotation'] = (origdata.obs['Label'] == 'U')
        print('Splitting data into train and test set...')
        X_train, X_test, y_train, y_test = train_test_split(origdata.to_df(), origdata.obs.true_annotation, train_size = 0.8, random_state = 49)
        mtx = X_train.values
        obs = origdata.obs.loc[y_train.index]
        var = origdata.var
        traindata = anndata.AnnData(X = mtx, obs = obs, var = var)
        mtx_test = X_test.values
        obs_test = origdata.obs.loc[y_test.index]
        var_test = origdata.var
        testdata = anndata.AnnData(X = mtx_test, obs = obs_test, var = var_test)
    else:
        print('Using full dataset for feature selection...')
        traindata = origdata
    
    # save stuff for run report
    single_cells = len(traindata.obs)
    available_features = len(feature_list)
    feature_data = param_dict['feature_types'].split(', ')
    feature_types = param_dict['feature_data'].split(', ')

    # make a new directory for output if needed
    write_dir = work_dir + 'results/'
    if not os.path.isdir(write_dir):
        os.mkdir(write_dir)

    # remove batch effect
    if batch == True:
        sc.pp.combat(traindata, key = 'batch', covariates = None, inplace = True)

    print('Setting up features for training...')

    # create new AnnData object using all gene set features
    if genesets == True:
        X_ad = ldmethods.make_features(0, available_features, traindata, feature_dict, feature_list)
    else:
        X_ad = traindata

    # count live and dead cells
    num_dead = X_ad.obs.dead.sum()
    num_dead_0 = num_dead
    num_live = len(X_ad.obs.dead) - num_dead
    num_live_0 = num_live
    pct_dead_0 = num_dead_0 / single_cells
    pct_live_0 = num_live_0 / single_cells
    print('Initially, there are {} dead cells and {} live cells'.format(num_dead, num_live))

    # find features with high variance
    X_ad.var['variance'] = np.var(X_ad.X, axis = 0)
    X_ad.obs['variance'] = np.var(X_ad.X, axis = 1)
    selected_features = X_ad.var.sort_values(by = 'variance', ascending = False).index.to_list()[:500]
    final_train_ad = X_ad[:, selected_features]

    # scale
    scaler = StandardScaler()
    scaler.fit(final_train_ad.X)
    final_train = scaler.transform(final_train_ad.X)


    ###### TRAINING ######

    lin_model = svm.NuSVC(kernel = 'linear', random_state = 0)
    rbf_model = svm.NuSVC(kernel = 'rbf', gamma = 'auto', random_state = 0)

    lin_model.fit(final_train, X_ad.obs.true_annotation)
    rbf_model.fit(final_train, X_ad.obs.true_annotation)


    ###### TESTING ######

    print('Testing...')

    # predict on testing set
    if batch == True:
        sc.pp.combat(testdata, key = 'batch', covariates = None, inplace = True)
    
    if genesets == True:
        test_ad = ldmethods.make_features(0, len(selected_features), testdata, feature_dict, selected_features)
    else:
        test_ad = testdata[:, selected_features]
    
    scaler = StandardScaler()
    scaler.fit(test_ad.X)
    final_test = scaler.transform(test_ad.X)
    
    test_ad.obs['predicted_dead_lin_svm'] = lin_model.predict(final_test)
    test_ad.obs['predicted_dead_rbf_svm'] = rbf_model.predict(final_test)

    # evaluate performance and save results
    scores_df = pd.DataFrame(columns = ['sensitivity', 'specificity', 'precision', 'accuracy', 'F1_score'])
    sensitivity, specificity, precision, accuracy, F1_score = ldmethods.score_classifier(test_ad.obs.true_annotation, test_ad.obs.predicted_dead_lin_svm)
    scores_df.loc['lin_svm'] = [sensitivity, specificity, precision, accuracy, F1_score]

    test_results = '\n\n\n****** TESTING ******\n\n\nSVM with linear kernel\n----------------------\nSensitivity:\t' + str(round(sensitivity, 4)) + '\nSpecificity:\t' + str(round(specificity, 4)) + '\nPrecision:\t' + str(round(precision, 4)) + '\nAccuracy:\t' + str(round(accuracy, 4)) + '\nF1 score:\t' + str(round(F1_score, 4))

    sensitivity, specificity, precision, accuracy, F1_score = ldmethods.score_classifier(test_ad.obs.true_annotation, test_ad.obs.predicted_dead_rbf_svm)
    scores_df.loc['rbf_svm'] = [sensitivity, specificity, precision, accuracy, F1_score]

    test_results = test_results + '\n\nSVM with radial kernel\n----------------------\nSensitivity:\t' + str(round(sensitivity, 4)) + '\nSpecificity:\t' + str(round(specificity, 4)) + '\nPrecision:\t' + str(round(precision, 4)) + '\nAccuracy:\t' + str(round(accuracy, 4)) + '\nF1 score:\t' + str(round(F1_score, 4))

    # plot umap of testing data
    ldmethods.plot_final_features(test_ad, write_dir + 'plot_umap_testing_svm.png', columns = ['predicted_dead_lin_svm', 'predicted_dead_rbf_svm', 'true_annotation'])
    ldmethods.plot_classifier_scores(scores_df, write_dir)


    ###### SAVE RESULTS ######

    last_toc = time.process_time()
    runtime = last_toc - first_tic

    # generate run report
    run_report = 'RUN REPORT - SVM\n\n\n****** TRACKING ******\n\n\nDatetime:\t' + now.strftime('%Y/%m/%d %H:%M') + ' UTC\nRuntime:\t' + str(round(runtime, 2)) + ' sec\nVersion:\t' + __version__ + '\n\nDirectory:\t' + write_dir + '\n\n\n****** DATA ******\n\n\nSingle cells:\t\t' + str(single_cells) + '\nInitial dead:\t\t' + str(num_dead_0) + ',\t' + str(round(pct_dead_0 * 100, 2)) + '%\nInitial live: \t\t' + str(num_live_0) + ',\t' + str(round(pct_live_0 * 100, 2)) + '%\n\nTotal features:\t\t' + str(available_features) + '\nFeature type:\t\t' + ', '.join(feature_types) + '\nData in features:\t' + ', '.join(feature_data) + test_results + '\n\n\nEOF'

    with open(write_dir + 'run_report.txt', "w") as text_file:
        text_file.write(run_report)

    print('Done')